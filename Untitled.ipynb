{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('../data/train/train.csv')\n",
    "test_df = pd.read_csv('../data/test/test.csv')\n",
    "sub = pd.DataFrame(test_df['time'])\n",
    " \n",
    "\n",
    "train_df = train_df[train_df['temperature'].notnull()]\n",
    "train_df = train_df.fillna(method='bfill')\n",
    "test_df = test_df.fillna(method='bfill')\n",
    " \n",
    "train_df.columns = ['time','year','month','day','hour','min','sec','outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo', 'temperature']\n",
    "test_df.columns = ['time','year','month','day','hour','min','sec','outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']\n",
    "\n",
    "\n",
    "data_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "\n",
    "# 基本聚合特征\n",
    "group_feats = []\n",
    "for f in tqdm(['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']):\n",
    "    data_df['MDH_{}_medi'.format(f)] = data_df.groupby(['month','day','hour'])[f].transform('median')\n",
    "    data_df['MDH_{}_mean'.format(f)] = data_df.groupby(['month','day','hour'])[f].transform('mean')\n",
    "    data_df['MDH_{}_max'.format(f)] = data_df.groupby(['month','day','hour'])[f].transform('max')\n",
    "    data_df['MDH_{}_min'.format(f)] = data_df.groupby(['month','day','hour'])[f].transform('min')\n",
    "    data_df['MDH_{}_std'.format(f)] = data_df.groupby(['month','day','hour'])[f].transform('std')\n",
    "\n",
    "    group_feats.append('MDH_{}_medi'.format(f))\n",
    "    group_feats.append('MDH_{}_mean'.format(f))\n",
    "    \n",
    "# 基本交叉特征\n",
    "for f1 in tqdm(['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']+group_feats):\n",
    "    \n",
    "    for f2 in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']+group_feats:\n",
    "        if f1 != f2:\n",
    "            colname = '{}_{}_ratio'.format(f1, f2)\n",
    "            data_df[colname] = data_df[f1].values / data_df[f2].values\n",
    "\n",
    "data_df = data_df.fillna(method='bfill')\n",
    "\n",
    "# 历史信息提取\n",
    "data_df['dt'] = data_df['day'].values + (data_df['month'].values - 3) * 31\n",
    "\n",
    "for f in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo', 'temperature']:\n",
    "    tmp_df = pd.DataFrame()\n",
    "    for t in tqdm(range(15, 45)):\n",
    "        tmp = data_df[data_df['dt']<t].groupby(['hour'])[f].agg({'mean'}).reset_index()\n",
    "        tmp.columns = ['hour','hit_{}_mean'.format(f)]\n",
    "        tmp['dt'] = t\n",
    "        tmp_df = tmp_df.append(tmp)\n",
    "    \n",
    "    data_df = data_df.merge(tmp_df, on=['dt','hour'], how='left')\n",
    "    \n",
    "data_df = data_df.fillna(method='bfill')\n",
    "\n",
    "\n",
    "# 离散化\n",
    "for f in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']:\n",
    "    data_df[f+'_20_bin'] = pd.cut(data_df[f], 20, duplicates='drop').apply(lambda x:x.left).astype(int)\n",
    "    data_df[f+'_50_bin'] = pd.cut(data_df[f], 50, duplicates='drop').apply(lambda x:x.left).astype(int)\n",
    "    data_df[f+'_100_bin'] = pd.cut(data_df[f], 100, duplicates='drop').apply(lambda x:x.left).astype(int)\n",
    "    data_df[f+'_200_bin'] = pd.cut(data_df[f], 200, duplicates='drop').apply(lambda x:x.left).astype(int)\n",
    "    \n",
    "for f1 in tqdm(['outdoorTemp_20_bin','outdoorHum_20_bin','outdoorAtmo_20_bin','indoorHum_20_bin','indoorAtmo_20_bin']):\n",
    "    for f2 in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']:\n",
    "        data_df['{}_{}_medi'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "        data_df['{}_{}_mean'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "        data_df['{}_{}_max'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "        data_df['{}_{}_min'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "       \n",
    "        \n",
    "for f1 in tqdm(['outdoorTemp_50_bin','outdoorHum_50_bin','outdoorAtmo_50_bin','indoorHum_50_bin','indoorAtmo_50_bin']):\n",
    "    for f2 in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']:\n",
    "        data_df['{}_{}_medi'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "        data_df['{}_{}_mean'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "        data_df['{}_{}_max'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "        data_df['{}_{}_min'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "        \n",
    "for f1 in tqdm(['outdoorTemp_100_bin','outdoorHum_100_bin','outdoorAtmo_100_bin','indoorHum_100_bin','indoorAtmo_100_bin']):\n",
    "    for f2 in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']:\n",
    "        data_df['{}_{}_medi'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "        data_df['{}_{}_mean'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "        data_df['{}_{}_max'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "        data_df['{}_{}_min'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "        \n",
    "for f1 in tqdm(['outdoorTemp_200_bin','outdoorHum_200_bin','outdoorAtmo_200_bin','indoorHum_200_bin','indoorAtmo_200_bin']):\n",
    "    for f2 in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']:\n",
    "        data_df['{}_{}_medi'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "        data_df['{}_{}_mean'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "        data_df['{}_{}_max'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "        data_df['{}_{}_min'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "\n",
    "\n",
    "def single_model(clf, train_x, train_y, test_x, clf_name, class_num=1):\n",
    "\n",
    "    train = np.zeros((train_x.shape[0], class_num))\n",
    "    test = np.zeros((test_x.shape[0], class_num))\n",
    "    \n",
    "    nums = int(train_x.shape[0] * 0.80)\n",
    "    \n",
    "    if clf_name in ['sgd','ridge']:\n",
    "        print('MinMaxScaler...')\n",
    "        for col in features:\n",
    "            ss = MinMaxScaler()\n",
    "            ss.fit(np.vstack([train_x[[col]].values, test_x[[col]].values]))\n",
    "            train_x[col] = ss.transform(train_x[[col]].values).flatten()\n",
    "            test_x[col] = ss.transform(test_x[[col]].values).flatten()\n",
    "    \n",
    "    trn_x, trn_y, val_x, val_y = train_x[:nums], train_y[:nums], train_x[nums:], train_y[nums:]\n",
    "    \n",
    "    if clf_name == \"lgb\":\n",
    "        train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "        valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "        data_matrix  = clf.Dataset(train_x, label=train_y)\n",
    "        \n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'mse',\n",
    "            'min_child_weight': 5,\n",
    "            'num_leaves': 2 ** 8,\n",
    "            'feature_fraction': 0.5,\n",
    "            'bagging_fraction': 0.5,\n",
    "            'bagging_freq': 1,\n",
    "            'learning_rate': 0.001,\n",
    "            'seed': 2020\n",
    "        }\n",
    "\n",
    "        model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=500,early_stopping_rounds=1000)\n",
    "        model2 = clf.train(params, data_matrix, model.best_iteration)\n",
    "        val_pred = model.predict(val_x, num_iteration=model2.best_iteration).reshape(-1,1)\n",
    "        test_pred = model.predict(test_x, num_iteration=model2.best_iteration).reshape(-1,1)\n",
    "\n",
    "    if clf_name == \"xgb\":\n",
    "        train_matrix = clf.DMatrix(trn_x , label=trn_y, missing=np.nan)\n",
    "        valid_matrix = clf.DMatrix(val_x , label=val_y, missing=np.nan)\n",
    "        test_matrix  = clf.DMatrix(test_x, missing=np.nan)\n",
    "        params = {'booster': 'gbtree',\n",
    "                  'eval_metric': 'mae',\n",
    "                  'min_child_weight': 5,\n",
    "                  'max_depth': 8,\n",
    "                  'subsample': 0.5,\n",
    "                  'colsample_bytree': 0.5,\n",
    "                  'eta': 0.001,\n",
    "                  'seed': 2020,\n",
    "                  #'nthread': 36,\n",
    "                  'silent': True,\n",
    "                  }\n",
    "\n",
    "        watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "\n",
    "        model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=500, early_stopping_rounds=1000)\n",
    "        val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit).reshape(-1,1)\n",
    "        test_pred = model.predict(test_matrix , ntree_limit=model.best_ntree_limit).reshape(-1,1)\n",
    "\n",
    "    if clf_name == \"cat\":\n",
    "        params = {'learning_rate': 0.001, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',\n",
    "                  'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}\n",
    "\n",
    "        model = clf(iterations=20000, **params)\n",
    "        model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                  cat_features=[], use_best_model=True, verbose=500)\n",
    "\n",
    "        val_pred  = model.predict(val_x)\n",
    "        test_pred = model.predict(test_x)\n",
    "    \n",
    "    if clf_name == \"sgd\":\n",
    "        params = {\n",
    "            'loss': 'squared_loss',\n",
    "            'penalty': 'l2',\n",
    "            'alpha': 0.00001,\n",
    "            'random_state': 2020,\n",
    "        }\n",
    "        model = SGDRegressor(**params)\n",
    "        model.fit(trn_x, trn_y)\n",
    "        val_pred  = model.predict(val_x)\n",
    "        test_pred = model.predict(test_x)\n",
    "    \n",
    "    if clf_name == \"ridge\":\n",
    "        params = {\n",
    "                'alpha': 1.0,\n",
    "                'random_state': 2020,\n",
    "            }\n",
    "        model = Ridge(**params)\n",
    "        model.fit(trn_x, trn_y)\n",
    "        val_pred  = model.predict(val_x)\n",
    "        test_pred = model.predict(test_x)\n",
    "\n",
    "    \n",
    "    print(\"%s_mse_score:\" % clf_name, mean_squared_error(val_y, val_pred))\n",
    "    \n",
    "    return val_pred, test_pred\n",
    "\n",
    "\n",
    "def lgb_model(x_train, y_train, x_valid):\n",
    "    lgb_train, lgb_test = single_model(lgb, x_train, y_train, x_valid, \"lgb\", 1)\n",
    "    return lgb_train, lgb_test\n",
    "\n",
    "def xgb_model(x_train, y_train, x_valid):\n",
    "    xgb_train, xgb_test = single_model(xgb, x_train, y_train, x_valid, \"xgb\", 1)\n",
    "    return xgb_train, xgb_test\n",
    "\n",
    "def cat_model(x_train, y_train, x_valid):\n",
    "    cat_train, cat_test = single_model(CatBoostRegressor, x_train, y_train, x_valid, \"cat\", 1)\n",
    "    return cat_train, cat_test\n",
    "\n",
    "def sgd_model(x_train, y_train, x_valid):\n",
    "    sgd_train, sgd_test = single_model(SGDRegressor, x_train, y_train, x_valid, \"sgd\", 1)\n",
    "    return sgd_train, sgd_test\n",
    "\n",
    "def ridge_model(x_train, y_train, x_valid):\n",
    "    ridge_train, ridge_test = single_model(Ridge, x_train, y_train, x_valid, \"ridge\", 1)\n",
    "    return ridge_train, ridge_test\n",
    "\n",
    "\n",
    "drop_columns=[\"time\",\"year\",\"sec\",\"temperature\"]\n",
    "\n",
    "\n",
    "train_count = train_df.shape[0]\n",
    "train_df = data_df[:train_count].copy().reset_index(drop=True)\n",
    "test_df = data_df[train_count:].copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "features = train_df[:1].drop(drop_columns,axis=1).columns\n",
    "x_train = train_df[features]\n",
    "x_test = test_df[features]\n",
    "\n",
    "y_train = train_df['temperature'].values - train_df['outdoorTemp'].values\n",
    "\n",
    "xgb_train, xgb_test = xgb_model(x_train, y_train, x_test)\n",
    "lr_train, lr_test = ridge_model(x_train, y_train, x_test)\n",
    "\n",
    "sgd_train, sgd_test = sgd_model(x_train, y_train, x_test)\n",
    "\n",
    "lgb_train, lgb_test = lgb_model(x_train, y_train, x_test)\n",
    "\n",
    "\n",
    "\n",
    "cat_train, cat_test = cat_model(x_train, y_train, x_test)\n",
    "\n",
    "\n",
    "train_pred = (lr_train + sgd_train + lgb_train[:,0] + xgb_train[:,0] + cat_train) / 5\n",
    "test_pred = (lr_test + sgd_test + lgb_test[:,0] + xgb_test[:,0] + cat_test) / 5\n",
    "\n",
    "\n",
    "sub[\"temperature\"] = xgb_test[:,0] + test_df['outdoorTemp'].values\n",
    "sub.to_csv('sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
